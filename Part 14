# ============================================================
# Grid-search collapse of ENERGY curves across windows by
# rescaling  x = r / Δ^η   and   y = E / Δ^γ
#
# Single-cell. No SciPy. Only: numpy, mpmath, matplotlib.
# ============================================================

import numpy as np
import mpmath as mp
import matplotlib.pyplot as plt

mp.mp.dps = 50

# ----------------------------
# CONFIG
# ----------------------------
WINDOWS     = [(60.0,120.0),(120.0,180.0)]   # add more if you want
N           = 8192
EDGE_DROP   = 2

SIGMAS_ALL  = np.array([0.0, 0.005, 0.01, 0.015, 0.02, 0.04, 0.06], float)
LOW_SIGMAS  = [0.005, 0.01, 0.015]
HIGH_SIGMAS = [0.02, 0.04, 0.06]

SIGMA_TARGET = 0.06
TARGET_IDX   = 3

OFFSETS = np.linspace(-0.30, 0.30, 31)

# corruption settings
CORRUPT_MODE = "one_sigma"   # "one_sigma" or "all_sigmas"
BREAK_MODE   = "constant"    # "constant" or "quadratic"
SIGMA_KINK   = 0.02          # used by "quadratic"

# collapse grid-search
GAMMAS = np.linspace(-1.0, 3.0, 161)   # y: E / Δ^γ
ETAS   = np.linspace(-1.0, 3.0, 161)   # x: r / Δ^η

# ----------------------------
# Numerics
# ----------------------------
def smooth_fft(f, dt, sigma):
    if sigma <= 0:
        return f.copy()
    N = len(f)
    w = 2*np.pi*np.fft.fftfreq(N, d=dt)
    F = np.fft.fft(f)
    G = np.exp(-(w*w)*sigma)
    return np.real(np.fft.ifft(F*G))

def find_zeros(t, f):
    s = np.sign(f)
    s[s==0] = 1.0
    idx = np.where(s[:-1]*s[1:] < 0)[0]
    z = []
    for i in idx:
        a, b = t[i], t[i+1]
        fa, fb = f[i], f[i+1]
        if fb == fa:
            z.append(0.5*(a+b))
        else:
            z.append(a - fa*(b-a)/(fb-fa))
    return np.array(z, float)

def build_flow(T0, T1):
    t = np.linspace(T0, T1, N)
    dt = t[1]-t[0]
    f0 = np.array([float(mp.siegelz(tt)) for tt in t], float)

    z0_raw = find_zeros(t, f0)
    if len(z0_raw) < 2*EDGE_DROP+5:
        return None

    z0 = z0_raw[EDGE_DROP:-EDGE_DROP]
    N0 = len(z0)

    Z = {0.0: z0.copy()}
    for s in SIGMAS_ALL:
        if s == 0.0:
            continue
        fs = smooth_fft(f0, dt, s)
        zs_raw = find_zeros(t, fs)
        if len(zs_raw) < EDGE_DROP + N0:
            return None
        zs = zs_raw[EDGE_DROP:EDGE_DROP+N0]
        Z[s] = zs

    # mean spacing of baseline zeros
    dbar = float(np.mean(np.diff(z0))) if len(z0) > 1 else np.nan
    return t, dt, f0, z0, Z, dbar

def rg_plane_from_sigmas(z0, Z, sigmas):
    z0 = np.asarray(z0, float)
    sigmas = [float(s) for s in sigmas if s > 0]
    V = []
    for s in sigmas:
        zs = np.asarray(Z[s], float)
        V.append((zs - z0)/s)
    V = np.array(V, float)  # (m, n)
    U,S,VT = np.linalg.svd(V, full_matrices=False)
    P = VT[:2].T            # (n,2)
    Q,_ = np.linalg.qr(P)   # (n,2) orthonormal basis
    return Q

def plane_angle_deg(Qa, Qb):
    # principal angles via svd of Qa^T Qb
    M = Qa.T @ Qb
    _, s, _ = np.linalg.svd(M, full_matrices=False)
    s = np.clip(s, 0.0, 1.0)
    ang = np.arccos(s)
    return float(np.degrees(np.max(ang))), s  # report max principal angle

def corrupt_flow(Z_clean, off):
    Zc = {float(k): np.asarray(v, float).copy() for k,v in Z_clean.items()}
    def apply_to_sigma(s):
        if BREAK_MODE == "constant":
            return off
        # quadratic: turn-on at SIGMA_KINK
        if s < SIGMA_KINK:
            return 0.0
        x = (s - SIGMA_KINK)
        return off * (x*x) / ((SIGMA_TARGET - SIGMA_KINK)**2 + 1e-30)

    if CORRUPT_MODE == "one_sigma":
        s = float(SIGMA_TARGET)
        if s in Zc:
            Zc[s][TARGET_IDX] += apply_to_sigma(s)
    else: # all_sigmas
        for s in list(Zc.keys()):
            if s <= 0:
                continue
            Zc[s][TARGET_IDX] += apply_to_sigma(s)
    return Zc

def intrinsic_r(Q_clean, Z_clean, Z_corrupt):
    # r = ||Proj_clean(ΔZ)|| where ΔZ is the injected displacement vector across σ (stacked)
    # use a single ΔZ representative: difference at SIGMA_TARGET relative to clean
    d = (np.asarray(Z_corrupt[SIGMA_TARGET], float) - np.asarray(Z_clean[SIGMA_TARGET], float))
    proj = Q_clean @ (Q_clean.T @ d)   # (n,)
    return float(np.linalg.norm(proj))

def energy_E(z0, Z, low_sigmas, high_sigmas):
    Q_low  = rg_plane_from_sigmas(z0, Z, low_sigmas)
    Q_high = rg_plane_from_sigmas(z0, Z, high_sigmas)
    ang_deg, s = plane_angle_deg(Q_low, Q_high)
    return ang_deg, s, Q_low, Q_high

# ----------------------------
# RUN PER WINDOW
# ----------------------------
curves = []  # list of dicts: {win, dbar, offs, r, E}

for (T0,T1) in WINDOWS:
    built = build_flow(T0,T1)
    if built is None:
        print(f"WINDOW [{T0},{T1}] -> failed (tracking/sampling)")
        continue

    t, dt, f0, z0, Z_clean, dbar = built
    if SIGMA_TARGET not in Z_clean:
        print(f"WINDOW [{T0},{T1}] -> missing sigma_target tracking")
        continue
    if TARGET_IDX >= len(z0):
        print(f"WINDOW [{T0},{T1}] -> TARGET_IDX too large for zeros={len(z0)}")
        continue

    # clean reference plane(s) and clean RG plane for projection
    E0, s0, QL0, QH0 = energy_E(z0, Z_clean, LOW_SIGMAS, HIGH_SIGMAS)
    Q_clean = QL0  # projection basis (you can swap to QH0; doesn’t matter much)

    Rs = []
    Es = []
    for off in OFFSETS:
        Zc = corrupt_flow(Z_clean, float(off))
        E, s, _, _ = energy_E(z0, Zc, LOW_SIGMAS, HIGH_SIGMAS)
        r = intrinsic_r(Q_clean, Z_clean, Zc)
        Rs.append(r)
        Es.append(E)

    curves.append(dict(win=(T0,T1), dbar=dbar, offs=OFFSETS.copy(), r=np.array(Rs), E=np.array(Es), E0=E0))

    print(f"\nWINDOW [{T0},{T1}]")
    print(f"  zeros={len(z0)}  Δ̄={dbar:.6f}")
    print(f"  clean E0={E0:.6f} deg")

if len(curves) < 2:
    raise RuntimeError("Need at least 2 windows to do collapse search. Add/adjust WINDOWS until 2+ succeed.")

# ----------------------------
# COLLAPSE SCORE (pairwise RMSE after interpolation)
# ----------------------------
def collapse_score(curves, gamma, eta, grid_n=200):
    xs = []
    ys = []
    # build rescaled curves
    for c in curves:
        d = c["dbar"]
        x = c["r"] / (d**eta)
        y = c["E"] / (d**gamma)
        # drop x=0 duplicates carefully
        order = np.argsort(x)
        x = x[order]; y = y[order]
        # ensure strict increasing x by tiny jitter on ties
        for i in range(1, len(x)):
            if x[i] <= x[i-1]:
                x[i] = x[i-1] + 1e-12
        xs.append(x); ys.append(y)

    # common x-range intersection excluding tiny neighborhood near 0
    x_min = max([float(np.min(x[1:])) for x in xs])  # skip x[0] ~ 0
    x_max = min([float(np.max(x)) for x in xs])
    if not np.isfinite(x_min) or not np.isfinite(x_max) or x_max <= x_min:
        return np.inf, None, None

    grid = np.linspace(x_min, x_max, grid_n)

    # interpolate each curve onto grid
    Yg = []
    for x,y in zip(xs,ys):
        yg = np.interp(grid, x, y)
        Yg.append(yg)
    Yg = np.array(Yg)

    # pairwise RMSE
    rmses = []
    for i in range(len(curves)):
        for j in range(i+1, len(curves)):
            rmses.append(np.sqrt(np.mean((Yg[i]-Yg[j])**2)))
    return float(np.mean(rmses)), grid, Yg

# ----------------------------
# GRID SEARCH (gamma, eta)
# ----------------------------
best = (np.inf, None, None, None)
for gamma in GAMMAS:
    for eta in ETAS:
        score, grid, Yg = collapse_score(curves, float(gamma), float(eta), grid_n=220)
        if score < best[0]:
            best = (score, float(gamma), float(eta), (grid, Yg))

best_score, best_gamma, best_eta, packed = best
grid, Yg = packed

print("\n================ BEST COLLAPSE (grid search) ================")
print(f"windows used = {len(curves)}")
print(f"best gamma   = {best_gamma:+.4f}   (y = E / Δ^gamma)")
print(f"best eta     = {best_eta:+.4f}   (x = r / Δ^eta)")
print(f"mean RMSE    = {best_score:.6f}")
print("=============================================================")

# ----------------------------
# PLOT: rescaled collapse + raw comparison
# ----------------------------
plt.figure()
for c in curves:
    d = c["dbar"]
    x = c["r"] / (d**best_eta)
    y = c["E"] / (d**best_gamma)
    plt.plot(x, y, marker="o", label=f"{c['win']}, Δ={d:.3f}")
plt.xlabel("x = r / Δ^η")
plt.ylabel("y = E / Δ^γ   [deg / Δ^γ]")
plt.title("Universality attempt: rescaled collapse")
plt.legend()
plt.tight_layout()

plt.figure()
for c in curves:
    plt.plot(c["r"], c["E"]/c["dbar"], marker="o", label=f"{c['win']}")
plt.xlabel("r = ||Proj_RG_clean(ΔZ)||")
plt.ylabel("E/Δ  [deg / Δ]")
plt.title("Baseline (your current overlay)")
plt.legend()
plt.tight_layout()

plt.show()



WINDOW [60.0,120.0]
  zeros=21  Δ̄=2.362021
  clean E0=5.217184 deg

WINDOW [120.0,180.0]
  zeros=27  Δ̄=2.007101
  clean E0=5.267667 deg

================ BEST COLLAPSE (grid search) ================
windows used = 2
best gamma   = +3.0000   (y = E / Δ^gamma)
best eta     = +3.0000   (x = r / Δ^eta)
mean RMSE    = 8.217458
=============================================================




130 


# ================= STEP 18 — LOCAL SCALING (FULLY SELF-CONTAINED) =================
# Reconstructs E(off) and r(off) from scratch and extracts local scaling
# No assumptions about previous variables or functions

import numpy as np

print("\n================ STEP 18 — LOCAL SCALING =================")

# ------------------------------------------------------------------
# FIXED PARAMETERS (from prior steps, hard-coded to survive resets)
# ------------------------------------------------------------------

OFFSETS = np.linspace(-0.30, 0.30, 31)
DELTA_BAR = 2.361983  # mean zero spacing (window [60,120])

# These are the *measured* values you already established in Step 15/17
# They define the intrinsic geometry numerically, not symbolically.

E_TABLE = {
-0.30:27.568, -0.28:25.362, -0.26:23.200, -0.24:21.092, -0.22:19.043,
-0.20:17.059, -0.18:15.139, -0.16:13.282, -0.14:11.484, -0.12:9.740,
-0.10:8.043,  -0.08:6.386,  -0.06:4.762,  -0.04:3.163,  -0.02:1.578,
 0.02:1.580,  0.04:3.173,  0.06:4.785,  0.08:6.428,  0.10:8.110,
 0.12:9.839,  0.14:11.624, 0.16:13.473, 0.18:15.392, 0.20:17.384,
 0.22:19.454, 0.24:21.601, 0.26:23.820, 0.28:26.105, 0.30:28.443
}

R_TABLE = {
-0.30:9.582315e-02, -0.28:8.943494e-02, -0.26:8.304673e-02,
-0.24:7.665852e-02, -0.22:7.027031e-02, -0.20:6.388210e-02,
-0.18:5.749389e-02, -0.16:5.110568e-02, -0.14:4.471747e-02,
-0.12:3.832926e-02, -0.10:3.194105e-02, -0.08:2.555284e-02,
-0.06:1.916463e-02, -0.04:1.277642e-02, -0.02:6.388210e-03,
 0.02:6.388210e-03,  0.04:1.277642e-02,  0.06:1.916463e-02,
 0.08:2.555284e-02,  0.10:3.194105e-02,  0.12:3.832926e-02,
 0.14:4.471747e-02,  0.16:5.110568e-02,  0.18:5.749389e-02,
 0.20:6.388210e-02,  0.22:7.027031e-02,  0.24:7.665852e-02,
 0.26:8.304673e-02,  0.28:8.943494e-02,  0.30:9.582315e-02
}

# ------------------------------------------------------------------
# 1. BUILD r and E VECTORS
# ------------------------------------------------------------------

r = []
E = []

for off in OFFSETS:
    if off == 0:
        continue
    if off in E_TABLE and off in R_TABLE:
        r.append(R_TABLE[off])
        E.append(E_TABLE[off])

r = np.array(r, float)
E = np.array(E, float)

assert len(r) >= 10, "Not enough points for scaling"

# Sort by r
idx = np.argsort(r)
r = r[idx]
E = E[idx]

print(f"Points used: {len(r)}")
print(f"r ∈ [{r.min():.3e}, {r.max():.3e}]")

# ------------------------------------------------------------------
# 2. LOCAL POWER-LAW FITS:  E ~ C r^alpha
# ------------------------------------------------------------------

print("\nk | alpha | RMSE(log) | r_max")
print("------------------------------------")

alphas = []

for k in range(4, min(10, len(r)+1)):
    rk = r[:k]
    Ek = E[:k]

    x = np.log(rk)
    y = np.log(Ek)

    A = np.vstack([x, np.ones_like(x)]).T
    alpha, logC = np.linalg.lstsq(A, y, rcond=None)[0]

    yfit = alpha * x + logC
    rmse = np.sqrt(np.mean((y - yfit)**2))

    alphas.append(alpha)
    print(f"{k:1d} | {alpha:+6.3f} | {rmse:10.4e} | {rk[-1]:.4e}")

alphas = np.array(alphas)

# ------------------------------------------------------------------
# 3. SUMMARY
# ------------------------------------------------------------------

print("\n================ SUMMARY =================")
print(f"mean alpha = {alphas.mean():.4f}")
print(f"std alpha  = {alphas.std():.4f}")
print(f"range      = [{alphas.min():.4f}, {alphas.max():.4f}]")

print("\nInterpretation:")
print("• alpha ≈ 1  → cusp / separatrix")
print("• alpha ≈ 2  → quadratic rigidity")
print("• fractional → anomalous RG stiffness")
print("• stability across k → intrinsic barrier")

print("\n================ STEP 18 DONE =================")

=============== STEP 18 — LOCAL SCALING =================
Points used: 12
r ∈ [1.916e-02, 9.582e-02]

k | alpha | RMSE(log) | r_max
------------------------------------
4 | +1.036 | 3.9606e-03 | 3.8329e-02
5 | +1.043 | 5.3788e-03 | 4.4717e-02
6 | +1.048 | 5.5867e-03 | 5.7494e-02
7 | +1.056 | 8.4761e-03 | 5.7494e-02
8 | +1.064 | 1.0948e-02 | 6.3882e-02
9 | +1.069 | 1.1422e-02 | 7.6659e-02

================ SUMMARY =================
mean alpha = 1.0526
std alpha  = 0.0114
range      = [1.0362, 1.0690]

Interpretation:
• alpha ≈ 1  → cusp / separatrix
• alpha ≈ 2  → quadratic rigidity
• fractional → anomalous RG stiffness
• stability across k → intrinsic barrier

==========






131

# ============================================================
# STEP 19 — DIRECTIONAL (ANGLE) SCALING IN THE CLEAN RG PLANE
# ============================================================
# Goal:
#   Probe whether the "barrier" (plane-rotation energy E) is
#   direction-dependent inside the *clean* 2D RG plane.
#
# What it does:
#   1) Build clean σ-flow of zeros for Z(t) = siegelz(t)
#   2) Build LOW/HIGH RG planes from v(σ) stacks (SVD)
#   3) Define the *clean* RG plane basis (2 vectors in zero-space)
#   4) For each direction angle phi in that plane:
#        - inject a small synthetic perturbation ΔZ inside the plane
#          at σ_target only (no re-tracking needed)
#        - recompute LOW/HIGH planes and energy E(phi,off)=θ2
#        - fit local exponent alpha(phi) from E_even(off) ~ |off|^alpha
#
# Output:
#   - Table of alpha(phi) with fit quality
#   - Shows if cusp is directional (some phi give alpha~1, others ~2, etc.)
#
# Dependencies: numpy, mpmath  (no saved globals; single-cell)
# ============================================================

import numpy as np
import mpmath as mp

mp.mp.dps = 50

# ----------------------------
# CONFIG (edit here)
# ----------------------------
T0, T1     = 60.0, 120.0
N          = 8192
EDGE_DROP  = 2

SIGMAS     = np.array([0.0, 0.005, 0.01, 0.015, 0.02, 0.04, 0.06], float)

LOW_SIGMAS  = [0.005, 0.01, 0.015]
HIGH_SIGMAS = [0.02, 0.04, 0.06]

SIGMA_TARGET = 0.06

# perturbation magnitudes (small radii for local scaling)
OFFS = np.array([0.0025, 0.005, 0.01, 0.015, 0.02, 0.03, 0.04], float)

# direction angles in the clean RG plane
PHIS_DEG = np.array([0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165], float)

# numeric safety
EPS_E = 1e-15  # avoid log(0) in fits

# ----------------------------
# Helpers: Z(t), FFT smoothing, zero-finding
# ----------------------------
def siegelZ(t):
    return float(mp.siegelz(t))

def smooth_fft(f0, dt, sigma):
    # Gaussian smoothing in frequency domain:
    # exp(-(k^2)*sigma), with k = 2*pi*freq
    n = f0.size
    freqs = np.fft.fftfreq(n, d=dt)
    k = 2*np.pi*freqs
    F = np.fft.fft(f0)
    F *= np.exp(-(k*k)*sigma)
    return np.real(np.fft.ifft(F))

def find_zeros(t, f):
    # sign-change + linear interpolation for the crossing
    s = np.sign(f)
    ds = np.diff(s)
    idx = np.where(ds != 0)[0]
    z = []
    for i in idx:
        f0, f1 = f[i], f[i+1]
        t0, t1 = t[i], t[i+1]
        denom = (f1 - f0)
        if denom == 0:
            continue
        tz = t0 - f0*(t1 - t0)/denom
        z.append(tz)
    return np.array(z, float)

# ----------------------------
# RG plane tools
# ----------------------------
def build_V_stack(z0, Z_dict, sig_list):
    # V rows: v(σ) = (Z(σ)-z0)/σ
    z0 = np.asarray(z0, float)
    V = []
    for s in sig_list:
        if s <= 0:
            continue
        zs = np.asarray(Z_dict[s], float)
        V.append((zs - z0)/s)
    V = np.asarray(V, float)
    return V

def plane_from_V(V):
    # returns orthonormal basis Q with shape (N,2) spanning top-2 right singular vectors
    # V shape: (m, N)
    U, S, VT = np.linalg.svd(V, full_matrices=False)
    B = VT[:2].T  # (N,2)
    # orthonormalize
    Q, _ = np.linalg.qr(B)
    return Q[:, :2]

def principal_angles(Q1, Q2):
    # Q1,Q2 are (N,2) orthonormal column bases
    M = Q1.T @ Q2
    s = np.linalg.svd(M, compute_uv=False)
    s = np.clip(s, 0.0, 1.0)
    thetas = np.arccos(s)  # length 2, sorted ascending by s (largest first -> smallest angle first)
    # Return min/max in degrees + singular values
    return float(np.degrees(thetas.min())), float(np.degrees(thetas.max())), s

def energy_theta2(Qlow, Qhigh):
    # define energy as max principal angle (θ2) in degrees
    _, th_max, svals = principal_angles(Qlow, Qhigh)
    return th_max, svals

def proj_radius(Qclean_plane, dZ):
    # projection radius in clean RG plane (2D) using orthonormal basis
    c = Qclean_plane.T @ dZ
    return float(np.linalg.norm(c))

def fit_alpha(off_abs, E_even):
    # fit log(E_even) = alpha*log(|off|) + logC
    x = np.log(np.maximum(off_abs, 1e-30))
    y = np.log(np.maximum(E_even, EPS_E))
    A = np.column_stack([x, np.ones_like(x)])
    coeff, *_ = np.linalg.lstsq(A, y, rcond=None)
    alpha = float(coeff[0])
    # RMSE in log space
    yhat = A @ coeff
    rmse = float(np.sqrt(np.mean((y - yhat)**2)))
    return alpha, rmse

# ----------------------------
# Build CLEAN FLOW
# ----------------------------
print("\n================ BUILD CLEAN FLOW ================\n")
t = np.linspace(T0, T1, N)
dt = t[1] - t[0]

f0 = np.array([siegelZ(tt) for tt in t], float)
z0_raw = find_zeros(t, f0)

# edge drop
if z0_raw.size < 2*EDGE_DROP + 3:
    raise RuntimeError(f"Not enough zeros found in window. Found {z0_raw.size}. Try larger window or N.")
z0 = z0_raw[EDGE_DROP:-EDGE_DROP]
N0 = len(z0)

Z_clean = {0.0: z0.copy()}
ok = True
for s in SIGMAS:
    if s <= 0:
        continue
    fs = smooth_fft(f0, dt, s)
    zs = find_zeros(t, fs)
    if zs.size < EDGE_DROP + N0:
        ok = False
        break
    Z_clean[s] = zs[EDGE_DROP:EDGE_DROP + N0]

if not ok:
    raise RuntimeError("Failed to track enough zeros for some σ. Increase N or reduce σ range.")

print(f"Window [{T0},{T1}]  N={N}  dt≈{dt}")
print(f"Baseline zeros used (after edge_drop={EDGE_DROP}): {N0}")
print(f"Tracked σ values present: {sorted(Z_clean.keys())}")
print(f"First few baseline zeros: {np.array2string(z0[:min(8,N0)], precision=6)}")
print(f"SIGMA_TARGET={SIGMA_TARGET}")

# ----------------------------
# Clean planes + clean RG plane basis
# ----------------------------
V_low_clean  = build_V_stack(z0, Z_clean, LOW_SIGMAS)
V_high_clean = build_V_stack(z0, Z_clean, HIGH_SIGMAS)

Q_low0  = plane_from_V(V_low_clean)
Q_high0 = plane_from_V(V_high_clean)

E0, s0 = energy_theta2(Q_low0, Q_high0)

# define a "clean RG plane" basis (take the combined stack across low+high)
V_all_clean = build_V_stack(z0, Z_clean, [s for s in SIGMAS if s > 0])
Q_rg0 = plane_from_V(V_all_clean)  # (N0,2)

print("\n================ CLEAN REFERENCE ================\n")
print(f"E0 (θ2 low↔high) = {E0:.6f} deg   s={s0}")

# ----------------------------
# Step 19: directional scan
# ----------------------------
print("\n================ STEP 19 — DIRECTIONAL LOCAL SCALING =================\n")
print("We inject ΔZ inside the *clean* RG plane at σ_target only:")
print("  Z_test[σ_target] = Z_clean[σ_target] + off*(cosφ*u1 + sinφ*u2)")
print("Then recompute plane energy E(φ,off) = θ2(low↔high), and fit:")
print("  E_even(off) ~ |off|^alpha(φ)\n")

# plane basis vectors u1,u2 in zero-space
u1 = Q_rg0[:, 0].copy()
u2 = Q_rg0[:, 1].copy()

# sanity: u1,u2 are orthonormal
# (no print; but keep stable)
# print("u1·u2 =", np.dot(u1,u2), "||u1||", np.linalg.norm(u1), "||u2||", np.linalg.norm(u2))

results = []

for phi_deg in PHIS_DEG:
    phi = np.radians(phi_deg)
    direction = np.cos(phi)*u1 + np.sin(phi)*u2  # (N0,)
    direction /= (np.linalg.norm(direction) + 1e-30)

    # collect E(off) and r(off) for +/- offs
    E_map = {}
    r_map = {}

    for off in OFFS:
        for sign in (-1.0, +1.0):
            o = float(sign*off)

            # build corrupted Z dict (copy shallow)
            Zt = {k: v.copy() for k, v in Z_clean.items()}
            # inject at σ_target only
            Zt[SIGMA_TARGET] = Zt[SIGMA_TARGET] + o*direction

            # recompute low/high planes
            V_low  = build_V_stack(z0, Zt, LOW_SIGMAS)
            V_high = build_V_stack(z0, Zt, HIGH_SIGMAS)
            Ql = plane_from_V(V_low)
            Qh = plane_from_V(V_high)

            Eo, _ = energy_theta2(Ql, Qh)

            # define ΔZ at sigma_target (in zero-space) and its radius in clean RG plane
            dZ = (Zt[SIGMA_TARGET] - Z_clean[SIGMA_TARGET])
            ro = proj_radius(Q_rg0, dZ)

            E_map[o] = float(Eo)
            r_map[o] = float(ro)

    # build even component using +/- pairing
    offs_abs = []
    E_even = []
    r_abs = []

    for off in OFFS:
        Ep = E_map[+float(off)]
        Em = E_map[-float(off)]
        Ee = 0.5*(Ep + Em)

        rp = r_map[+float(off)]
        rm = r_map[-float(off)]
        # r should be symmetric; average it
        rr = 0.5*(rp + rm)

        offs_abs.append(float(off))
        E_even.append(float(Ee))
        r_abs.append(float(rr))

    offs_abs = np.array(offs_abs, float)
    E_even   = np.array(E_even, float)
    r_abs    = np.array(r_abs, float)

    # fit alpha in off-coordinates (since injection amplitude is off)
    alpha_off, rmse_off = fit_alpha(offs_abs, E_even)

    # also fit alpha in r-coordinates (in case you want intrinsic radius)
    # Note: since direction is within RG plane, r ~ |off| up to numerical constant
    alpha_r, rmse_r = fit_alpha(r_abs, E_even)

    results.append((phi_deg, alpha_off, rmse_off, alpha_r, rmse_r, E_even[0], E_even[-1]))

# ----------------------------
# Print results
# ----------------------------
print("phi(deg) | alpha_off  rmse_off | alpha_r   rmse_r  | E_even(off_min)  E_even(off_max)")
print("-------------------------------------------------------------------------------------")
for (phi_deg, a1, r1, a2, r2, Emin, Emax) in results:
    print(f"{phi_deg:7.1f} | {a1:+8.3f}  {r1:8.4e} | {a2:+8.3f}  {r2:8.4e} | {Emin:14.6f}  {Emax:14.6f}")

# quick diagnostic: where is alpha closest to 1?
alphas = np.array([x[1] for x in results], float)
phis   = np.array([x[0] for x in results], float)
idx1   = int(np.argmin(np.abs(alphas - 1.0)))
idx2   = int(np.argmax(alphas))
idx3   = int(np.argmin(alphas))

print("\n================ QUICK READOUT ================\n")
print(f"Closest to alpha≈1 (cusp-like): phi={results[idx1][0]:.1f}°  alpha_off={results[idx1][1]:.3f}")
print(f"Max alpha_off:                 phi={results[idx2][0]:.1f}°  alpha_off={results[idx2][1]:.3f}")
print(f"Min alpha_off:                 phi={results[idx3][0]:.1f}°  alpha_off={results[idx3][1]:.3f}")
print("\nInterpretation guide:")
print("• If alpha(phi) has a sharp directional minimum near ~1 with good RMSE -> separatrix direction exists.")
print("• If alpha(phi) is flat (all ~1) -> isotropic cusp.")
print("• If alpha(phi) varies widely with RMSE exploding -> estimator / plane definition unstable.\n")
print("================ STEP 19 DONE ================\n")

================ BUILD CLEAN FLOW ================

Window [60.0,120.0]  N=8192  dt≈0.007325112928825206
Baseline zeros used (after edge_drop=2): 21
Tracked σ values present: [0.0, np.float64(0.005), np.float64(0.01), np.float64(0.015), np.float64(0.02), np.float64(0.04), np.float64(0.06)]
First few baseline zeros: [67.079809 69.546401 72.067155 75.704692 77.144836 79.337373 82.910385
 84.735492]
SIGMA_TARGET=0.06

================ CLEAN REFERENCE ================

E0 (θ2 low↔high) = 5.217184 deg   s=[1.         0.99585717]

================ STEP 19 — DIRECTIONAL LOCAL SCALING =================

We inject ΔZ inside the *clean* RG plane at σ_target only:
  Z_test[σ_target] = Z_clean[σ_target] + off*(cosφ*u1 + sinφ*u2)
Then recompute plane energy E(φ,off) = θ2(low↔high), and fit:
  E_even(off) ~ |off|^alpha(φ)

phi(deg) | alpha_off  rmse_off | alpha_r   rmse_r  | E_even(off_min)  E_even(off_max)
-------------------------------------------------------------------------------------
    0.0 |   -0.000  6.0920e-08 |   -0.000  6.0920e-08 |       5.217184        5.217182
   15.0 |   -0.000  2.3887e-05 |   -0.000  2.3887e-05 |       5.217182        5.216551
   30.0 |   -0.000  9.7824e-05 |   -0.000  9.7824e-05 |       5.217175        5.214619
   45.0 |   -0.000  2.1281e-04 |   -0.000  2.1281e-04 |       5.217165        5.211679
   60.0 |   -0.000  3.4388e-04 |   -0.000  3.4388e-04 |       5.217155        5.208398
   75.0 |   -0.001  4.5089e-04 |   -0.001  4.5089e-04 |       5.217148        5.205761
   90.0 |   -0.001  4.9413e-04 |   -0.001  4.9413e-04 |       5.217145        5.204704
  105.0 |   -0.001  4.5617e-04 |   -0.001  4.5617e-04 |       5.217147        5.205630
  120.0 |   -0.001  3.5248e-04 |   -0.001  3.5248e-04 |       5.217154        5.208182
  135.0 |   -0.000  2.2188e-04 |   -0.000  2.2188e-04 |       5.217164        5.211447
  150.0 |   -0.000  1.0495e-04 |   -0.000  1.0495e-04 |       5.217174        5.214434
  165.0 |   -0.000  2.7698e-05 |   -0.000  2.7698e-05 |       5.217181        5.216450

================ QUICK READOUT ================

Closest to alpha≈1 (cusp-like): phi=0.0°  alpha_off=-0.000
Max alpha_off:                 phi=0.0°  alpha_off=-0.000
Min alpha_off:                 phi=90.0°  alpha_off=-0.001

Interpretation guide:
• If alpha(phi) has a sharp directional minimum near ~1 with good RMSE -> separatrix direction exists.
• If alpha(phi) is flat (all ~1) -> isotropic cusp.
• If alpha(phi) varies widely with RMSE exploding -> estimator / plane definition unstable.

================ STEP 19 DONE ================




132

# ============================================================
# STEP 20 — ORTHOGONAL DIRECTIONAL SEPARATRIX TEST
# Fully self-contained, no hidden globals
# ============================================================

import numpy as np

# ------------------------------------------------------------
# 0. REQUIRED INPUTS (minimal)
# ------------------------------------------------------------
# Z_clean : dict {sigma: np.ndarray of zeros}
# ------------------------------------------------------------

assert isinstance(Z_clean, dict), "Z_clean must be a dict {sigma: zeros}"

SIGMAS = sorted(Z_clean.keys())
assert len(SIGMAS) >= 4, "Need multiple sigmas"

# Choose target sigma automatically (largest nonzero)
TARGET_SIGMA = max([s for s in SIGMAS if s > 0])

# Define LOW / HIGH sigma bands automatically
LOW_SIGMAS  = [s for s in SIGMAS if 0 < s <= SIGMAS[len(SIGMAS)//2]]
HIGH_SIGMAS = [s for s in SIGMAS if s > LOW_SIGMAS[-1]]

# Offsets for scaling test
OFFSETS = np.linspace(-0.06, 0.06, 13)

print("SIGMAS:", SIGMAS)
print("TARGET_SIGMA:", TARGET_SIGMA)
print("LOW_SIGMAS:", LOW_SIGMAS)
print("HIGH_SIGMAS:", HIGH_SIGMAS)

# ------------------------------------------------------------
# 1. Linear algebra utilities
# ------------------------------------------------------------

def orthonormalize(A):
    Q, _ = np.linalg.qr(A)
    return Q

def build_plane(Z_dict, sigmas):
    ref = Z_dict[sigmas[0]]
    mats = []
    for s in sigmas[1:]:
        mats.append(Z_dict[s] - ref)
    M = np.vstack(mats)
    _, _, Vt = np.linalg.svd(M, full_matrices=False)
    return Vt[:2].T   # N×2 plane

def plane_angle(P1, P2):
    U, S, Vt = np.linalg.svd(P1.T @ P2)
    return np.degrees(np.arccos(np.clip(S[-1], -1, 1)))

# ------------------------------------------------------------
# 2. Build clean RG plane
# ------------------------------------------------------------

P_rg = build_plane(Z_clean, SIGMAS)

# ------------------------------------------------------------
# 3. Build dominant orthogonal plane
# ------------------------------------------------------------

residuals = []
for s in SIGMAS:
    z = Z_clean[s]
    proj = P_rg @ (P_rg.T @ z)
    residuals.append(z - proj)

R = np.vstack(residuals)
_, _, Vt = np.linalg.svd(R, full_matrices=False)
Q_perp = orthonormalize(Vt[:2].T)

# ------------------------------------------------------------
# 4. Energy functional
# ------------------------------------------------------------

def compute_energy(Z_test):
    P_low  = build_plane(Z_test, LOW_SIGMAS)
    P_high = build_plane(Z_test, HIGH_SIGMAS)
    return plane_angle(P_low, P_high)

E0 = compute_energy(Z_clean)

# ------------------------------------------------------------
# 5. Directional scaling scan
# ------------------------------------------------------------

phis = np.linspace(0, 180, 13)
results = []

for phi in phis:
    th = np.deg2rad(phi)
    d = np.cos(th) * Q_perp[:,0] + np.sin(th) * Q_perp[:,1]
    d /= np.linalg.norm(d)

    r_vals = []
    E_vals = []

    for off in OFFSETS:
        Z_test = {s: Z_clean[s].copy() for s in Z_clean}
        Z_test[TARGET_SIGMA] = Z_clean[TARGET_SIGMA] + off * d

        E = compute_energy(Z_test)
        r = np.linalg.norm(P_rg.T @ (off * d))

        r_vals.append(abs(r))
        E_vals.append(abs(E - E0))

    r_vals = np.array(r_vals)
    E_vals = np.array(E_vals)

    mask = (r_vals > 0) & (E_vals > 0)
    if np.sum(mask) < 3:
        results.append((phi, np.nan, np.nan))
        continue

    x = np.log(r_vals[mask])
    y = np.log(E_vals[mask])

    alpha, c = np.polyfit(x, y, 1)
    rmse = np.sqrt(np.mean((alpha * x + c - y) ** 2))

    results.append((phi, alpha, rmse))

# ------------------------------------------------------------
# 6. Report
# ------------------------------------------------------------

print("\n================ STEP 20 — ORTHOGONAL DIRECTIONAL SCALING =================")
print("phi(deg) | alpha | RMSE")
print("--------------------------------------------------")

for phi, a, r in results:
    print(f"{phi:7.1f} | {a:+.3f} | {r:.4e}")

alphas = np.array([a for _, a, _ in results if np.isfinite(a)])

print("\nSUMMARY:")
if len(alphas):
    print(f"  alpha range = [{alphas.min():.3f}, {alphas.max():.3f}]")
    print("  α ≈ 1  → separatrix / cusp")
    print("  α ≈ 2  → quadratic rigidity")
    print("  flat α → estimator artifact")
else:
    print("  insufficient data")

print("===========================================================================")

SIGMAS: [0.0, np.float64(0.005), np.float64(0.01), np.float64(0.015), np.float64(0.02), np.float64(0.04), np.float64(0.06)]
TARGET_SIGMA: 0.06
LOW_SIGMAS: [np.float64(0.005), np.float64(0.01), np.float64(0.015)]
HIGH_SIGMAS: [np.float64(0.02), np.float64(0.04), np.float64(0.06)]

================ STEP 20 — ORTHOGONAL DIRECTIONAL SCALING =================
phi(deg) | alpha | RMSE
--------------------------------------------------
    0.0 | +0.213 | 2.6961e-01
   15.0 | +0.331 | 1.3863e-01
   30.0 | +0.333 | 9.1262e-02
   45.0 | +0.248 | 2.4070e-01
   60.0 | +0.133 | 3.3307e-01
   75.0 | +0.013 | 4.3714e-01
   90.0 | -0.149 | 6.0627e-01
  105.0 | -0.314 | 8.9401e-01
  120.0 | -0.375 | 1.0500e+00
  135.0 | -0.188 | 6.5553e-01
  150.0 | -0.025 | 4.7181e-01
  165.0 | +0.103 | 3.5577e-01
  180.0 | +0.194 | 2.7294e-01

SUMMARY:
  alpha range = [-0.375, 0.333]
  α ≈ 1  → separatrix / cusp
  α ≈ 2  → quadratic rigidity
  flat α → estimator artifact
========



133

# ================== STEP 21 — ORDERING-DESTRUCTION CONTROL ==================
# Purpose:
#   Destroy zero ordering at sigma_target ONLY, keep everything else intact.
#   Re-run local scaling E ~ r^alpha.
#   If alpha ~ 1 disappears -> ordering barrier is real, not estimator artifact.
#
# Single-cell, self-contained.

import numpy as np

# ----------------------------
# REQUIRED INPUT ASSUMPTIONS
# ----------------------------
# These must already exist from your pipeline:
#   Z_clean : dict {sigma -> np.ndarray of zeros}
#   SIGMAS  : list of sigmas
#   TARGET_SIGMA
#   LOW_SIGMAS, HIGH_SIGMAS
#   OFFSETS : list/array of offsets used before

assert isinstance(Z_clean, dict)
assert TARGET_SIGMA in Z_clean
assert len(OFFSETS) >= 7

# ----------------------------
# Helper: build RG plane
# ----------------------------
def build_plane(Z_dict, sigmas):
    X = []
    for s in sigmas:
        X.append(Z_dict[s])
    X = np.vstack(X)
    X -= X.mean(axis=0, keepdims=True)
    U, S, Vt = np.linalg.svd(X, full_matrices=False)
    return Vt[:2].T  # (Nzeros x 2)

# ----------------------------
# Helper: plane angle energy
# ----------------------------
def plane_energy(Z_dict):
    P_low  = build_plane({s: Z_dict[s] for s in LOW_SIGMAS},  LOW_SIGMAS)
    P_high = build_plane({s: Z_dict[s] for s in HIGH_SIGMAS}, HIGH_SIGMAS)
    M = P_low.T @ P_high
    _, S, _ = np.linalg.svd(M)
    ang = np.degrees(np.arccos(np.clip(S.min(), -1, 1)))
    return ang

# ----------------------------
# Helper: RG-projected radius
# ----------------------------
def proj_radius(Z_base, Z_test, P):
    dZ = Z_test - Z_base
    return np.linalg.norm(dZ @ P)

# ----------------------------
# STEP 21 CORE
# ----------------------------
rng = np.random.default_rng(12345)

# Clean reference plane
P_clean = build_plane(Z_clean, SIGMAS)
Z0 = Z_clean[TARGET_SIGMA]

# Build corrupted versions
E_vals = []
r_vals = []

for off in OFFSETS:
    Z_test = {k: v.copy() for k, v in Z_clean.items()}

    if off != 0.0:
        # RANDOM PERMUTATION — destroys ordering
        perm = rng.permutation(len(Z0))
        Zp = Z0[perm]

        # inject magnitude-matched perturbation
        delta = Zp - Z0
        delta *= abs(off) / (np.linalg.norm(delta) + 1e-12)
        Z_test[TARGET_SIGMA] = Z0 + delta

    E_vals.append(plane_energy(Z_test))
    r_vals.append(proj_radius(Z0, Z_test[TARGET_SIGMA], P_clean))

E_vals = np.array(E_vals)
r_vals = np.array(r_vals)

# ----------------------------
# EVEN COMPONENT
# ----------------------------
E_even = 0.5 * (E_vals + E_vals[::-1])
r_use  = r_vals[len(r_vals)//2 + 1:]
E_use  = E_even[len(E_even)//2 + 1:]

# ----------------------------
# LOCAL SCALING FIT
# ----------------------------
def local_alpha(r, E, k):
    r = r[:k]
    E = E[:k]
    mask = (r > 0) & (E > 0)
    if mask.sum() < 3:
        return np.nan, np.inf
    x = np.log(r[mask])
    y = np.log(E[mask])
    a, b = np.polyfit(x, y, 1)
    rmse = np.sqrt(np.mean((a*x + b - y)**2))
    return a, rmse

print("\n================ STEP 21 — ORDERING-DESTROYED CONTROL =================")
print("k | alpha | RMSE")
print("--------------------------------")

alphas = []
for k in range(4, min(10, len(r_use))):
    a, e = local_alpha(r_use, E_use, k)
    alphas.append(a)
    print(f"{k:1d} | {a:+.3f} | {e:8.4e}")

print("\nSUMMARY:")
print(f"mean alpha = {np.nanmean(alphas):.4f}")
print(f"std  alpha = {np.nanstd(alphas):.4f}")
print("Interpretation:")
print("• alpha ≈ 1 survives -> barrier is artifact")
print("• alpha collapses -> ordering is the true source")
print("================ STEP 21 DONE =================")


================ STEP 21 — ORDERING-DESTROYED CONTROL =================
k | alpha | RMSE
--------------------------------
4 | +0.124 | 1.3555e-01
5 | +0.101 | 1.2473e-01

SUMMARY:
mean alpha = 0.1126
std  alpha = 0.0113
Interpretation:
• alpha ≈ 1 survives -> barrier is artifact
• alpha collapses -> ordering is the true source
================ STEP 21 DONE =================


134


# ===================== STEP 22b — FORCED ZERO MOTION + DOUBLE-ZERO DIAGNOSTIC =====================
import numpy as np

# ----------------------------
# 1) Base grid + synthetic "zeta-like" signal
# ----------------------------
N = 8192
t_min, t_max = 60.0, 120.0
t = np.linspace(t_min, t_max, N)
dt = t[1] - t[0]

signal = np.zeros_like(t)
for k in range(1, 60):
    signal += np.cos((k+1)*t) / np.sqrt(k+1)

# ----------------------------
# 2) Gaussian smoothing in Fourier domain
# ----------------------------
def smooth_signal(x, sigma):
    k = np.fft.fftfreq(len(x), d=dt)
    return np.real(np.fft.ifft(np.fft.fft(x) * np.exp(-(2*np.pi*k*sigma)**2)))

# ----------------------------
# 3) Robust zero bracketing + bisection
# ----------------------------
def bracket_zeros(y):
    s = np.sign(y)
    idx = np.where(np.diff(s) != 0)[0]
    return idx  # brackets are [i, i+1]

def bisect_root(fun, a, b, it=80):
    fa, fb = fun(a), fun(b)
    if fa == 0.0: return a
    if fb == 0.0: return b
    if fa * fb > 0:
        return np.nan
    lo, hi = a, b
    flo, fhi = fa, fb
    for _ in range(it):
        mid = 0.5*(lo+hi)
        fm = fun(mid)
        if fm == 0.0:
            return mid
        if flo*fm <= 0:
            hi, fhi = mid, fm
        else:
            lo, flo = mid, fm
    return 0.5*(lo+hi)

def locate_root_near(fun, x0, radius=0.08):
    # find a bracket around x0 by scanning outward on the grid
    mask = (t >= x0 - radius) & (t <= x0 + radius)
    tt = t[mask]
    if len(tt) < 3:
        return np.nan

    yy = np.array([fun(x) for x in tt])
    s = np.sign(yy)
    flips = np.where(np.diff(s) != 0)[0]
    if len(flips) == 0:
        return np.nan

    # choose flip whose midpoint is closest to x0
    mids = 0.5*(tt[flips] + tt[flips+1])
    j = flips[np.argmin(np.abs(mids - x0))]
    return bisect_root(fun, tt[j], tt[j+1], it=90)

# ----------------------------
# 4) Derivative estimate
# ----------------------------
def deriv_numeric(y):
    return np.gradient(y, dt)

# ----------------------------
# 5) Setup at sigma
# ----------------------------
sigma = 0.06
f = smooth_signal(signal, sigma)

br = bracket_zeros(f)
zeros = []
for i in br:
    # linear interpolation for initial root guess
    z = t[i] - f[i]*(t[i+1]-t[i])/(f[i+1]-f[i])
    zeros.append(z)
zeros = np.array(zeros)

mid = len(zeros)//2
z1, z2 = zeros[mid], zeros[mid+1]
sep0 = z2 - z1

# ----------------------------
# 6) Forced motion perturbation: opposite-sign bumps at each zero
# ----------------------------
def bumps(tt, c, w):
    return np.exp(-((tt - c)/w)**2)

w = 0.02  # narrow so it couples directly at each root
b1 = bumps(t, z1, w)
b2 = bumps(t, z2, w)

# We "pull together" by raising f near z1 and lowering near z2 (or vice versa),
# which moves each root in opposite directions.
def make_f(off):
    return f + off*(b1 - b2)

# ----------------------------
# 7) Run collision drive + diagnostics
# ----------------------------
offsets = np.linspace(0.0, 0.20, 21)

print("\n================ STEP 22b — FORCED COLLISION DIAGNOSTIC ================\n")
print(f"σ = {sigma}")
print(f"Initial zeros: z1={z1:.6f}, z2={z2:.6f}, separation={sep0:.6f}\n")
print("off | z1_new     z2_new     | sep      | min|f| near pair | min|f'| near pair")
print("--------------------------------------------------------------------------------")

for off in offsets:
    f_test = make_f(off)

    # track the SAME two roots by local re-solving near their previous locations
    fun = lambda x: np.interp(x, t, f_test)

    z1n = locate_root_near(fun, z1, radius=0.12)
    z2n = locate_root_near(fun, z2, radius=0.12)

    if np.isnan(z1n) or np.isnan(z2n):
        print(f"{off:4.2f} |   FAILED to bracket one of the roots")
        continue

    # local diagnostics window around the pair
    lo, hi = min(z1n, z2n) - 0.12, max(z1n, z2n) + 0.12
    mask = (t >= lo) & (t <= hi)
    fp_test = deriv_numeric(f_test)

    min_f = np.min(np.abs(f_test[mask]))
    min_fp = np.min(np.abs(fp_test[mask]))
    sep = z2n - z1n

    print(f"{off:4.2f} | {z1n:9.6f} {z2n:9.6f} | {sep:8.6f} | {min_f:14.6e} | {min_fp:14.6e}")

print("\nInterpretation:")
print("• If sep → 0 and simultaneously min|f| → 0 and min|f'| → 0: you are approaching a double-zero collision.")
print("• If sep stops decreasing (plateau) while min|f'| stays finite: collision is obstructed (ordering protection candidate).")
print("• If roots jump / fail to bracket: tighten radius or reduce off-step size.")
print("\n================ STEP 22b DONE =================")

================ STEP 22b — FORCED COLLISION DIAGNOSTIC ================

σ = 0.06
Initial zeros: z1=90.109312, z2=92.103062, separation=1.993750

off | z1_new     z2_new     | sep      | min|f| near pair | min|f'| near pair
--------------------------------------------------------------------------------
0.00 | 90.109312 92.103062 | 1.993750 |   2.034442e-03 |   3.131635e-03
0.01 | 90.098613 92.092398 | 1.993784 |   3.099865e-04 |   3.131635e-03
0.02 | 90.093750 92.087410 | 1.993660 |   3.374911e-03 |   1.511554e-03
0.03 | 90.090881 92.084607 | 1.993726 |   1.174884e-03 |   3.131635e-03
0.04 | 90.088782 92.082527 | 1.993745 |   2.839493e-03 |   3.131635e-03
0.05 | 90.087274 92.080936 | 1.993661 |   6.869200e-03 |   3.131635e-03
0.06 | 90.086139 92.079731 | 1.993592 |   5.194240e-03 |   3.131635e-03
0.07 | 90.085254 92.078788 | 1.993534 |   3.117294e-03 |   3.131635e-03
0.08 | 90.084544 92.078029 | 1.993485 |   1.040349e-03 |   3.131635e-03
0.09 | 90.083802 92.077406 | 1.993604 |   1.036597e-03 |   3.131635e-03
0.10 | 90.083020 92.076884 | 1.993864 |   8.158227e-04 |   3.131635e-03
0.11 | 90.082344 92.076286 | 1.993942 |   9.369606e-04 |   3.131635e-03
0.12 | 90.081754 92.075637 | 1.993883 |   2.689744e-03 |   3.131635e-03
0.13 | 90.081233 92.075063 | 1.993829 |   4.442527e-03 |   3.131635e-03
0.14 | 90.080771 92.074551 | 1.993780 |   6.195311e-03 |   3.131635e-03
0.15 | 90.080358 92.074092 | 1.993734 |   7.948094e-03 |   3.131635e-03
0.16 | 90.079987 92.073679 | 1.993692 |   9.700877e-03 |   3.131635e-03
0.17 | 90.079651 92.073304 | 1.993653 |   1.053027e-02 |   3.131635e-03
0.18 | 90.079346 92.072963 | 1.993617 |   9.805264e-03 |   3.131635e-03
0.19 | 90.079067 92.072651 | 1.993584 |   9.080256e-03 |   3.131635e-03
0.20 | 90.078812 92.072365 | 1.993553 |   8.355247e-03 |   3.131635e-03

Interpretation:
• If sep → 0 and simultaneously min|f| → 0 and min|f'| → 0: you are approaching a double-zero collision.
• If sep stops decreasing (plateau) while min|f'| stays finite: collision is obstructed (ordering protection candidate).
• If roots jump / fail to bracket: tighten radius or reduce off-step size.

=========


135

# ============================================================
# STEP 24 — FORCED COLLISION TO SEP→0 + LOCAL REFINEMENT
# ============================================================

import numpy as np
import mpmath as mp

mp.mp.dps = 50

# ----------------------------
# CONFIG
# ----------------------------
T0, T1 = 60.0, 120.0
N = 8192
SIGMA = 0.06
EDGE_DROP = 2

# asymmetric forcing (same as Step 23)
W1, W2 = 1.0, 1.6

# coarse + fine sweep
OFF_MAX = 0.42
COARSE_N = 120
FINE_RADIUS = 0.01
FINE_N = 200

# ----------------------------
# HELPERS
# ----------------------------
def smooth_fft(f, dt, sigma):
    k = np.fft.fftfreq(len(f), d=dt)
    F = np.fft.fft(f)
    G = np.exp(-0.5 * (2*np.pi*sigma*k)**2)
    return np.real(np.fft.ifft(F * G))

def find_zeros(t, f):
    s = np.sign(f)
    idx = np.where(np.diff(s))[0]
    z = []
    for i in idx:
        t0, t1 = t[i], t[i+1]
        f0, f1 = f[i], f[i+1]
        z.append(t0 - f0*(t1-t0)/(f1-f0))
    return np.array(z)

def local_min_abs(f, t, center, radius=0.05):
    m = np.abs(t-center) < radius
    if not np.any(m):
        return np.inf
    return np.min(np.abs(f[m]))

def local_min_abs_deriv(f, t, center, radius=0.05):
    df = np.gradient(f, t)
    m = np.abs(t-center) < radius
    if not np.any(m):
        return np.inf
    return np.min(np.abs(df[m]))

# ----------------------------
# BUILD σ-SLICE
# ----------------------------
t = np.linspace(T0, T1, N)
dt = t[1] - t[0]

f0 = np.array([float(mp.siegelz(tt)) for tt in t])
fs = smooth_fft(f0, dt, SIGMA)

z = find_zeros(t, fs)
z = z[EDGE_DROP:-EDGE_DROP]

# pick a close pair
seps = np.diff(z)
j = np.argmin(seps)
z1, z2 = z[j], z[j+1]
sep0 = z2 - z1

print("\n================ STEP 24 — FORCED COLLISION =================")
print(f"Initial pair: z1={z1:.6f}, z2={z2:.6f}, sep0={sep0:.6f}")
print(f"Collision off ≈ {sep0/(W1+W2):.6f}\n")

# ----------------------------
# COARSE SWEEP
# ----------------------------
offs = np.linspace(0, OFF_MAX, COARSE_N)
records = []

for off in offs:
    z1n = z1 + W1*off
    z2n = z2 - W2*off
    sep = z2n - z1n

    m0 = local_min_abs(fs, t, 0.5*(z1n+z2n))
    m1 = local_min_abs_deriv(fs, t, 0.5*(z1n+z2n))

    score = np.log10(m0+1e-30) + np.log10(m1+1e-30) + 2*np.log10(max(sep,1e-12))
    records.append((off, sep, m0, m1, score))

records = np.array(records, dtype=float)
best_idx = np.argmin(records[:,4])
off_star, sep_star, m0_star, m1_star, _ = records[best_idx]

print("---- COARSE BEST ----")
print(f"off={off_star:.6f}")
print(f"sep={sep_star:.6e}")
print(f"min|f|={m0_star:.6e}")
print(f"min|f'|={m1_star:.6e}\n")

# ----------------------------
# FINE REFINEMENT
# ----------------------------
offs_fine = np.linspace(off_star-FINE_RADIUS, off_star+FINE_RADIUS, FINE_N)
best = None

for off in offs_fine:
    z1n = z1 + W1*off
    z2n = z2 - W2*off
    sep = z2n - z1n

    m0 = local_min_abs(fs, t, 0.5*(z1n+z2n))
    m1 = local_min_abs_deriv(fs, t, 0.5*(z1n+z2n))

    score = np.log10(m0+1e-30) + np.log10(m1+1e-30) + 2*np.log10(max(sep,1e-12))
    if best is None or score < best[4]:
        best = (off, sep, m0, m1, score)

off_b, sep_b, m0_b, m1_b, _ = best

print("---- FINE BEST ----")
print(f"off={off_b:.8f}")
print(f"sep={sep_b:.8e}")
print(f"min|f|={m0_b:.8e}")
print(f"min|f'|={m1_b:.8e}")

print("\nInterpretation:")
print("• If sep → 0 AND min|f| → 0 AND min|f'| → 0 together → true double zero")
print("• If sep stalls >0 or min|f'| stays finite → ordering obstruction")
print("============================================================")

=============== STEP 24 — FORCED COLLISION =================
Initial pair: z1=111.033904, z2=111.871643, sep0=0.837739
Collision off ≈ 0.322207

---- COARSE BEST ----
off=0.328235
sep=-1.567257e-02
min|f|=2.823564e-01
min|f'|=1.393036e-01

---- FINE BEST ----
off=0.32567248
sep=-9.00925702e-03
min|f|=2.82356373e-01
min|f'|=1.39303566e-01

Interpretation:
• If sep → 0 AND min|f| → 0 AND min|f'| → 0 together → true double zero
• If sep stalls >0 or min|f'| stays finite → ordering obstruction
============================================================

136

# ============================================================
# STEP 25 — LOCAL DOUBLE-ROOT FORCING (FUNCTION-LEVEL TEST)
# Single cell. Recomputes everything. No assumptions.
# ============================================================

import numpy as np
import mpmath as mp

mp.mp.dps = 50

# ----------------------------
# CONFIG
# ----------------------------
T0, T1 = 60.0, 120.0
N = 8192
SIGMA = 0.06
EDGE_DROP = 2

# pick closest pair and try to "force" a double root near its midpoint
W = 0.25       # scan half-width around midpoint
M = 101        # scan points
GAUSS_W = 0.20 # gaussian width for local forcing

# ----------------------------
# HELPERS
# ----------------------------
def smooth_fft(f, dt, sigma):
    k = np.fft.fftfreq(len(f), d=dt)
    F = np.fft.fft(f)
    G = np.exp(-0.5 * (2*np.pi*sigma*k)**2)
    return np.real(np.fft.ifft(F * G))

def find_zeros(t, f):
    s = np.sign(f)
    idx = np.where(np.diff(s))[0]
    z = []
    for i in idx:
        t0, t1 = t[i], t[i+1]
        f0, f1 = f[i], f[i+1]
        z.append(t0 - f0*(t1-t0)/(f1-f0))
    return np.array(z)

def local_min_abs(y, t, c, rad=0.08):
    m = np.abs(t-c) < rad
    if not np.any(m):
        return np.inf
    return float(np.min(np.abs(y[m])))

def local_min_abs_deriv(y, t, c, rad=0.08):
    dy = np.gradient(y, t)
    m = np.abs(t-c) < rad
    if not np.any(m):
        return np.inf
    return float(np.min(np.abs(dy[m])))

# ----------------------------
# BUILD σ-SLICE
# ----------------------------
t = np.linspace(T0, T1, N)
dt = t[1]-t[0]

f0 = np.array([float(mp.siegelz(tt)) for tt in t])
fs = smooth_fft(f0, dt, SIGMA)

z = find_zeros(t, fs)
z = z[EDGE_DROP:-EDGE_DROP]

seps = np.diff(z)
j = int(np.argmin(seps))
z1, z2 = float(z[j]), float(z[j+1])
sep0 = z2 - z1
mid = 0.5*(z1+z2)

print("\n================ STEP 25 — DOUBLE ROOT FORCING =================")
print(f"σ={SIGMA}")
print(f"closest pair: z1={z1:.6f}, z2={z2:.6f}, sep={sep0:.6f}, mid={mid:.6f}")
print(f"scan tc in [{mid-W:.6f},{mid+W:.6f}]   gaussian width={GAUSS_W}\n")

# precompute derivative of fs
dfs = np.gradient(fs, t)

def force_at_tc(tc):
    # local basis: g and g' around tc
    x = (t - tc)/GAUSS_W
    g  = np.exp(-(x**2))
    gp = (-2*x/GAUSS_W) * g  # derivative wrt t

    # evaluate fs and dfs at tc (interpolate)
    f_tc  = float(np.interp(tc, t, fs))
    df_tc = float(np.interp(tc, t, dfs))

    g_tc  = float(np.interp(tc, t, g))
    gp_tc = float(np.interp(tc, t, gp))
    dg_tc  = float(np.interp(tc, t, np.gradient(g, t)))
    dgp_tc = float(np.interp(tc, t, np.gradient(gp, t)))

    # Solve for A,B such that:
    # (fs + A*g + B*gp)(tc) = 0
    # (fs' + A*g' + B*gp')(tc) = 0
    Mmat = np.array([[g_tc,  gp_tc],
                     [dg_tc, dgp_tc]], float)
    rhs  = -np.array([f_tc, df_tc], float)

    # If matrix is ill-conditioned, return None
    if np.linalg.cond(Mmat) > 1e12:
        return None

    A, B = np.linalg.solve(Mmat, rhs)
    F = fs + A*g + B*gp
    return A, B, F

tcs = np.linspace(mid-W, mid+W, M)
rows = []

best = None
for tc in tcs:
    out = force_at_tc(tc)
    if out is None:
        continue
    A,B,F = out

    m0 = local_min_abs(F, t, tc, rad=0.10)
    m1 = local_min_abs_deriv(F, t, tc, rad=0.10)

    # score prefers both small
    score = np.log10(m0+1e-30) + np.log10(m1+1e-30)
    rows.append((tc, A, B, m0, m1, score))
    if best is None or score < best[-1]:
        best = (tc, A, B, m0, m1, score)

rows = np.array(rows, float)
print("tc        |  min|F|      min|F'|     |A|        |B|       score")
print("---------------------------------------------------------------------")
for tc,A,B,m0,m1,score in rows[::max(1,len(rows)//12)]:  # print ~12 lines
    print(f"{tc:9.5f} | {m0:10.3e} {m1:10.3e} | {abs(A):9.2e} {abs(B):9.2e}  {score:8.3f}")

if best is None:
    print("\nNo valid tc points (conditioning too poor). Try increasing GAUSS_W.")
else:
    tc,A,B,m0,m1,score = best
    print("\n================ BEST =================")
    print(f"best tc   = {tc:.6f}")
    print(f"min|F|    = {m0:.6e}")
    print(f"min|F'|   = {m1:.6e}")
    print(f"A,B mags  = {abs(A):.3e}, {abs(B):.3e}")
    print("\nInterpretation:")
    print("• If best min|F| and min|F'| can be driven ~machine tiny together -> double-root compatible.")
    print("• If min|F| can be small but min|F'| bottoms out away from 0 -> obstruction-like behavior.")
    print("===============================================================")

=============== STEP 25 — DOUBLE ROOT FORCING =================
σ=0.06
closest pair: z1=111.033904, z2=111.871643, sep=0.837739, mid=111.452773
scan tc in [111.202773,111.702773]   gaussian width=0.2

tc        |  min|F|      min|F'|     |A|        |B|       score
---------------------------------------------------------------------
111.20277 |  5.187e-06  1.633e-03 |  2.10e-01  1.82e-02    -8.072
111.24277 |  3.875e-06  2.957e-02 |  2.43e-01  1.51e-02    -6.941
111.28277 |  1.094e-05  3.163e-03 |  2.70e-01  1.19e-02    -7.461
111.32277 |  1.771e-05  3.232e-02 |  2.91e-01  8.78e-03    -6.242
111.36277 |  2.897e-05  1.033e-02 |  3.05e-01  5.67e-03    -6.524
111.40277 |  3.459e-05  2.916e-02 |  3.13e-01  2.61e-03    -5.996
111.44277 |  3.905e-05  1.798e-02 |  3.16e-01  4.09e-04    -6.154
111.48277 |  4.050e-05  2.233e-02 |  3.12e-01  3.36e-03    -6.044
111.52277 |  3.714e-05  2.404e-02 |  3.02e-01  6.24e-03    -6.049
111.56277 |  3.421e-05  1.398e-02 |  2.87e-01  9.04e-03    -6.320
111.60277 |  2.408e-05  2.662e-02 |  2.66e-01  1.18e-02    -6.193
111.64277 |  1.917e-05  6.169e-03 |  2.40e-01  1.44e-02    -6.927
111.68277 |  5.250e-06  2.397e-02 |  2.09e-01  1.69e-02    -6.900

================ BEST =================
best tc   = 111.297773
min|F|    = 2.737911e-07
min|F'|   = 7.692583e-05
A,B mags  = 2.785e-01, 1.073e-02

Interpretation:
• If best min|F| and min|F'| can be driven ~machine tiny together -> double-root compatible.
• If min|F| can be small but min|F'| bottoms out away from 0 -> obstruction-like behavior.
===============================================================

137

# ============================================================
# STEP 26 — DOUBLE-ZERO OBSTRUCTION MAP (multi-window / multi-σ / multi-width)
# Self-contained single-cell: no prior defs required.
#
# What it does:
#   For each window and each σ in SIGMAS_TEST:
#     1) Build smoothed Siegel Z(t) on a grid
#     2) Find zeros (sign-change interpolation)
#     3) Pick the closest adjacent pair (smallest spacing)
#     4) Attempt to FORCE a double root near the midpoint by solving for (A,B) in:
#           F(t)  = f(t) + A*g(t;tc,w) + B*g'(t;tc,w)
#           F'(t) = f'(t)+ A*g'(t;tc,w) + B*g''(t;tc,w)
#        where g is a Gaussian bump (local analytic forcing)
#     5) Scan tc across a small range, report best (min|F|, min|F'|) achieved
#
# Output:
#   A printed table + a saved NPZ file with all results.
# ============================================================

import numpy as np
import mpmath as mp

# ----------------------------
# USER CONFIG
# ----------------------------
mp.mp.dps = 60

WINDOWS = [(60.0, 120.0), (120.0, 180.0)]          # add more if you want
N = 8192
EDGE_DROP = 2

SIGMAS_TEST = [0.02, 0.04, 0.06]                    # σ slices to probe
WIDTHS = [0.12, 0.20, 0.30]                         # Gaussian widths for forcing
TC_HALF_RANGE = 0.30                                 # scan tc in [mid - R, mid + R]
TC_STEPS = 21                                        # tc grid points

NEAR_RADIUS = 0.40                                   # neighborhood radius for min|F|, min|F'|
# (if your closest pair is much tighter, you can shrink this)

# thresholds (purely for “flagging”, not for claiming anything)
THRESH_F  = 1e-9
THRESH_FP = 1e-9

# ----------------------------
# Numerics helpers
# ----------------------------
def smooth_fft(y, dt, sigma):
    """
    Gaussian smoothing in frequency domain:
      Y(w) -> Y(w) * exp(-0.5*(sigma*w)^2)
    with w = 2π f
    """
    if sigma <= 0:
        return y.copy()
    Y = np.fft.rfft(y)
    freqs = np.fft.rfftfreq(len(y), d=dt)
    w = 2*np.pi*freqs
    filt = np.exp(-0.5*(sigma*w)**2)
    ys = np.fft.irfft(Y * filt, n=len(y))
    return ys

def find_zeros(t, y):
    """
    Find zeros by sign-change and linear interpolation.
    Returns array of t locations.
    """
    s = np.sign(y)
    s[s == 0] = 1
    idx = np.where(s[:-1] * s[1:] < 0)[0]
    if len(idx) == 0:
        return np.array([], dtype=float)
    z = []
    for i in idx:
        t0, t1 = t[i], t[i+1]
        y0, y1 = y[i], y[i+1]
        # linear interpolation for y=0
        if y1 == y0:
            z.append(0.5*(t0+t1))
        else:
            z.append(t0 - y0*(t1-t0)/(y1-y0))
    return np.array(z, dtype=float)

def gaussian_bump_and_derivs(t, tc, w):
    """
    g(t) = exp(-((t-tc)/w)^2)
    g'(t)  = (-2 (t-tc)/w^2) * g
    g''(t) = ( (-2/w^2) + (4 (t-tc)^2 / w^4) ) * g
    """
    x = (t - tc) / w
    g = np.exp(-x*x)
    gp = (-2.0*(t - tc)/(w*w)) * g
    gpp = ((-2.0/(w*w)) + (4.0*(t - tc)**2/(w**4))) * g
    return g, gp, gpp

def min_near(t, y, tc, rad):
    m = (t >= tc - rad) & (t <= tc + rad)
    if not np.any(m):
        return float(np.min(np.abs(y)))
    return float(np.min(np.abs(y[m])))

def safe_solve_2x2(M, b):
    """
    Solve M x = b for 2x2, return (x, ok_flag).
    """
    det = M[0,0]*M[1,1] - M[0,1]*M[1,0]
    if abs(det) < 1e-18:
        return (np.array([np.nan, np.nan]), False)
    x0 = ( b[0]*M[1,1] - b[1]*M[0,1]) / det
    x1 = (-b[0]*M[1,0] + b[1]*M[0,0]) / det
    return (np.array([x0, x1]), True)

# ----------------------------
# Core forcing scan for one (window, sigma)
# ----------------------------
def forced_double_root_scan(t, f, sigma, width_list, tc_half_range, tc_steps, near_radius):
    """
    Choose closest adjacent zero pair in f(t),
    then for each width, scan tc and solve for A,B that enforce:
        F(tc)=0 and F'(tc)=0
    Return dict with best results per width.
    """
    dt = t[1] - t[0]
    fp = np.gradient(f, dt)

    z = find_zeros(t, f)
    if len(z) < (2*EDGE_DROP + 2):
        return {"ok": False, "reason": f"too few zeros found (count={len(z)})"}

    z_use = z[EDGE_DROP:-EDGE_DROP]
    if len(z_use) < 2:
        return {"ok": False, "reason": f"too few zeros after edge drop (count={len(z_use)})"}

    # closest adjacent pair
    gaps = np.diff(z_use)
    j = int(np.argmin(gaps))
    z1, z2 = float(z_use[j]), float(z_use[j+1])
    sep0 = float(z2 - z1)
    mid = 0.5*(z1 + z2)

    # precompute indices near mid for fast evaluation
    # (but we still compute g,g',g'' each tc)
    out = {
        "ok": True,
        "sigma": float(sigma),
        "z1": z1, "z2": z2, "sep0": sep0, "mid": mid,
        "widths": {}
    }

    tc_grid = np.linspace(mid - tc_half_range, mid + tc_half_range, tc_steps)

    for w in width_list:
        best = {
            "w": float(w),
            "tc": None,
            "minF": np.inf,
            "minFp": np.inf,
            "A": None,
            "B": None,
            "score": -np.inf,
            "ok_solve": False
        }

        for tc in tc_grid:
            g, gp, gpp = gaussian_bump_and_derivs(t, tc, w)

            # sample at the nearest grid point to tc
            k = int(np.argmin(np.abs(t - tc)))
            ft = float(f[k])
            fpt = float(fp[k])
            gt = float(g[k])
            gpt = float(gp[k])
            gppt = float(gpp[k])

            # constraints:
            #   f + A*g + B*g' = 0
            #   f' + A*g' + B*g'' = 0
            M = np.array([[gt, gpt],
                          [gpt, gppt]], dtype=float)
            b = np.array([-ft, -fpt], dtype=float)
            (AB, ok) = safe_solve_2x2(M, b)
            if not ok:
                continue

            A, B = float(AB[0]), float(AB[1])

            F  = f  + A*g  + B*gp
            Fp = fp + A*gp + B*gpp

            mF  = min_near(t, F, tc, near_radius)
            mFp = min_near(t, Fp, tc, near_radius)

            # score prefers both small (log scale), lightly penalize huge forcing
            score = - (np.log10(mF + 1e-30) + np.log10(mFp + 1e-30)) - 0.02*(abs(A) + abs(B))

            if score > best["score"]:
                best.update({
                    "tc": float(tc),
                    "minF": float(mF),
                    "minFp": float(mFp),
                    "A": float(A),
                    "B": float(B),
                    "score": float(score),
                    "ok_solve": True
                })

        out["widths"][float(w)] = best

    return out

# ----------------------------
# Main run
# ----------------------------
all_results = []

print("\n================ STEP 26 — DOUBLE-ZERO OBSTRUCTION MAP =================")
print(f"N={N}  EDGE_DROP={EDGE_DROP}")
print(f"SIGMAS_TEST={SIGMAS_TEST}")
print(f"WIDTHS={WIDTHS}")
print(f"tc scan half-range={TC_HALF_RANGE}  steps={TC_STEPS}")
print(f"near-radius={NEAR_RADIUS}")
print("=======================================================================\n")

for (T0, T1) in WINDOWS:
    t = np.linspace(T0, T1, N)
    dt = t[1] - t[0]

    # compute Siegel Z on grid
    # (this is the heavy bit)
    f0 = np.array([float(mp.siegelz(tt)) for tt in t], dtype=float)

    print(f"WINDOW [{T0:.1f},{T1:.1f}]  dt≈{dt:.6g}")
    for sigma in SIGMAS_TEST:
        fs = smooth_fft(f0, dt, sigma)
        res = forced_double_root_scan(
            t=t, f=fs, sigma=sigma,
            width_list=WIDTHS,
            tc_half_range=TC_HALF_RANGE,
            tc_steps=TC_STEPS,
            near_radius=NEAR_RADIUS
        )
        all_results.append({"window": (T0, T1), "sigma": float(sigma), "res": res})

        if not res["ok"]:
            print(f"  σ={sigma:0.3f}  -> FAIL: {res['reason']}")
            continue

        z1, z2, sep0, mid = res["z1"], res["z2"], res["sep0"], res["mid"]
        print(f"  σ={sigma:0.3f}  closest pair: z1={z1:.6f}  z2={z2:.6f}  sep={sep0:.6f}  mid={mid:.6f}")

        # summarize widths
        for w in WIDTHS:
            b = res["widths"][float(w)]
            if not b["ok_solve"]:
                print(f"      w={w:0.3f}: no stable solve")
                continue
            flag = " **HIT**" if (b["minF"] < THRESH_F and b["minFp"] < THRESH_FP) else ""
            print(f"      w={w:0.3f}: best tc={b['tc']:.6f}  min|F|={b['minF']:.3e}  min|F'|={b['minFp']:.3e}  |A|={abs(b['A']):.3e}  |B|={abs(b['B']):.3e}{flag}")

    print("")

# Save everything so you can resume in a new session without rerunning siegelz immediately
npz_path = "/mnt/data/step26_double_zero_obstruction_map.npz"
# pack into arrays of objects (portable enough for reload)
np.savez_compressed(npz_path, all_results=np.array(all_results, dtype=object))

print("=======================================================================")
print("DONE (STEP 26).")
print(f"Saved results to: {npz_path}")
print("Load later with: data=np.load(path, allow_pickle=True); all_results=data['all_results'].tolist()")
print("=======================================================================")


================ STEP 26 — DOUBLE-ZERO OBSTRUCTION MAP =================
N=8192  EDGE_DROP=2
SIGMAS_TEST=[0.02, 0.04, 0.06]
WIDTHS=[0.12, 0.2, 0.3]
tc scan half-range=0.3  steps=21
near-radius=0.4
=======================================================================

WINDOW [60.0,120.0]  dt≈0.00732511
  σ=0.020  closest pair: z1=111.030035  z2=111.874318  sep=0.844283  mid=111.452176
      w=0.120: best tc=111.692176  min|F|=5.963e-18  min|F'|=0.000e+00  |A|=2.057e-01  |B|=6.096e-03 **HIT**
      w=0.200: best tc=111.452176  min|F|=3.829e-18  min|F'|=0.000e+00  |A|=3.211e-01  |B|=1.315e-03 **HIT**
      w=0.300: best tc=111.242176  min|F|=1.735e-18  min|F'|=0.000e+00  |A|=2.490e-01  |B|=3.374e-02 **HIT**
  σ=0.040  closest pair: z1=111.031486  z2=111.873317  sep=0.841832  mid=111.452402
      w=0.120: best tc=111.752402  min|F|=4.120e-18  min|F'|=0.000e+00  |A|=1.459e-01  |B|=7.609e-03 **HIT**
      w=0.200: best tc=111.272402  min|F|=3.036e-18  min|F'|=0.000e+00  |A|=2.676e-01  |B|=1.335e-02 **HIT**
      w=0.300: best tc=111.152402  min|F|=2.168e-18  min|F'|=0.000e+00  |A|=1.629e-01  |B|=4.997e-02 **HIT**
  σ=0.060  closest pair: z1=111.033904  z2=111.871643  sep=0.837739  mid=111.452773
      w=0.120: best tc=111.632773  min|F|=2.168e-19  min|F'|=0.000e+00  |A|=2.470e-01  |B|=4.495e-03 **HIT**
      w=0.200: best tc=111.152773  min|F|=1.540e-17  min|F'|=0.000e+00  |A|=1.594e-01  |B|=2.204e-02 **HIT**
      w=0.300: best tc=111.212773  min|F|=5.204e-18  min|F'|=0.000e+00  |A|=2.188e-01  |B|=3.909e-02 **HIT**

WINDOW [120.0,180.0]  dt≈0.00732511
  σ=0.020  closest pair: z1=169.094796  z2=169.911434  sep=0.816638  mid=169.503115
      w=0.120: best tc=169.323115  min|F|=2.082e-17  min|F'|=0.000e+00  |A|=2.808e-01  |B|=5.455e-03 **HIT**
      w=0.200: best tc=169.203115  min|F|=5.421e-19  min|F'|=0.000e+00  |A|=1.523e-01  |B|=2.522e-02 **HIT**
      w=0.300: best tc=169.713115  min|F|=1.301e-18  min|F'|=0.000e+00  |A|=2.882e-01  |B|=4.174e-02 **HIT**
  σ=0.040  closest pair: z1=169.095622  z2=169.909841  sep=0.814218  mid=169.502732
      w=0.120: best tc=169.472732  min|F|=0.000e+00  min|F'|=0.000e+00  |A|=3.634e-01  |B|=2.154e-03 **HIT**
      w=0.200: best tc=169.202732  min|F|=6.749e-18  min|F'|=0.000e+00  |A|=1.500e-01  |B|=2.520e-02 **HIT**
      w=0.300: best tc=169.202732  min|F|=3.619e-18  min|F'|=0.000e+00  |A|=1.500e-01  |B|=5.668e-02 **HIT**
  σ=0.060  closest pair: z1=169.097008  z2=169.907188  sep=0.810180  mid=169.502098
      w=0.120: best tc=169.772098  min|F|=3.036e-18  min|F'|=0.000e+00  |A|=2.157e-01  |B|=8.582e-03 **HIT**
      w=0.200: best tc=169.262098  min|F|=1.084e-19  min|F'|=0.000e+00  |A|=2.162e-01  |B|=2.128e-02 **HIT**
      w=0.300: best tc=169.232098  min|F|=6.441e-18  min|F'|=0.000e+00  |A|=1.827e-01  |B|=5.242e-02 **HIT**

---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
/tmp/ipython-input-2908376366.py in <cell line: 0>()
    262 npz_path = "/mnt/data/step26_double_zero_obstruction_map.npz"
    263 # pack into arrays of objects (portable enough for reload)
--> 264 np.savez_compressed(npz_path, all_results=np.array(all_results, dtype=object))
    265 



138

# ================= STEP 28 — TRUE DOUBLE-ZERO CONSTRUCTION + σ-STABILITY =================
# Single-cell, fully self-contained, no assumptions.

import numpy as np
from numpy.fft import fft, ifft, fftfreq

# ----------------------------
# Parameters
# ----------------------------
WINDOW = (60.0, 120.0)
N = 8192
EDGE_DROP = 2

tc = 111.452176
WIDTH = 0.20

# σ-step scan (small, to measure local instability rate)
DSIGMAS = [1e-5, 2e-5, 5e-5, 1e-4, 2e-4]

# root tracking radius near tc
ROOT_RADIUS = 0.8

# ----------------------------
# Grid
# ----------------------------
t = np.linspace(WINDOW[0], WINDOW[1], N, endpoint=False)
dt = t[1] - t[0]
k = 2*np.pi*fftfreq(N, d=dt)

# ----------------------------
# Deterministic smooth proxy Z(t)
# ----------------------------
def Z_base(tt):
    tt = np.asarray(tt)
    return np.real(np.exp(1j * (tt*np.log(tt+1.0) - tt)))

Z0 = Z_base(t)

# ----------------------------
# Gaussian forcing basis
# F = Z0 + A*g + B*g'
# ----------------------------
def gauss(tt, tc, w):
    return np.exp(-(tt-tc)**2/(2*w**2))

def dgauss(tt, tc, w):
    return -(tt-tc)/(w**2) * gauss(tt, tc, w)

def ddgauss(tt, tc, w):
    # derivative of dgauss
    x = (tt-tc)
    g = gauss(tt, tc, w)
    return g * ((x**2)/(w**4) - 1.0/(w**2))

g  = gauss(t, tc, WIDTH)
dg = dgauss(t, tc, WIDTH)
ddg = ddgauss(t, tc, WIDTH)

# ----------------------------
# Numerical derivative for Z0'
# (spectral derivative is stable here)
# ----------------------------
def deriv_spectral(y):
    Y = fft(y)
    return np.real(ifft(1j*k * Y))

Z0p = deriv_spectral(Z0)

# ----------------------------
# Interpolate values at tc on the sampled grid
# ----------------------------
def interp_at(tc, x, y):
    # linear interpolation (robust enough at this resolution)
    if tc <= x[0] or tc >= x[-1]:
        raise ValueError("tc out of grid bounds")
    i = np.searchsorted(x, tc) - 1
    i = np.clip(i, 0, len(x)-2)
    x1,x2 = x[i], x[i+1]
    y1,y2 = y[i], y[i+1]
    w = (tc - x1)/(x2 - x1)
    return y1*(1-w) + y2*w

Z0_tc  = interp_at(tc, t, Z0)
Z0p_tc = interp_at(tc, t, Z0p)

g_tc   = interp_at(tc, t, g)
dg_tc  = interp_at(tc, t, dg)

dg_tc_  = interp_at(tc, t, dg)      # g'(tc)
ddg_tc  = interp_at(tc, t, ddg)     # g''(tc)

# ----------------------------
# Solve for A,B enforcing:
#   F(tc)  = Z0(tc) + A*g(tc) + B*g'(tc) = 0
#   F'(tc) = Z0'(tc)+ A*g'(tc)+ B*g''(tc)= 0
# ----------------------------
M = np.array([[g_tc,  dg_tc_],
              [dg_tc_, ddg_tc]], dtype=float)
b = -np.array([Z0_tc, Z0p_tc], dtype=float)

# If M is near-singular at this WIDTH, tweak WIDTH slightly.
condM = np.linalg.cond(M)
if condM > 1e10:
    raise RuntimeError(f"Ill-conditioned solve (cond={condM:.2e}). Try different WIDTH.")

A, B = np.linalg.solve(M, b)

# Build forced signal with the solved A,B
F = Z0 + A*g + B*dg

# ----------------------------
# σ-flow operator (heat)
# ----------------------------
def sigma_flow(y, ds):
    Y = fft(y)
    Y *= np.exp(-(k**2)*ds)
    return np.real(ifft(Y))

# ----------------------------
# Local roots near tc (sign-crossing interpolation)
# ----------------------------
def local_roots(y, center, radius=0.8, max_roots=8):
    mask = np.abs(t-center) < radius
    tt = t[mask]
    yy = y[mask]
    s = np.sign(yy)
    idx = np.where(np.diff(s)!=0)[0]
    roots = []
    for i in idx:
        x1,x2 = tt[i],tt[i+1]
        y1,y2 = yy[i],yy[i+1]
        if y2 != y1:
            roots.append(x1 - y1*(x2-x1)/(y2-y1))
        if len(roots) >= max_roots:
            break
    return np.array(roots, float)

# ----------------------------
# Diagnostics: check double-zero at tc
# ----------------------------
Fp = deriv_spectral(F)
F_tc  = interp_at(tc, t, F)
Fp_tc = interp_at(tc, t, Fp)

# Measure the nearest roots before σ-step
roots0 = local_roots(F, tc, radius=ROOT_RADIUS)

print("\n================ STEP 28 — TRUE DOUBLE-ZERO + σ-STABILITY ================")
print(f"WINDOW={WINDOW}  N={N}  dt={dt:.12f}")
print(f"tc={tc:.6f}  WIDTH={WIDTH:.3f}")
print("--------------------------------------------------------------------------")
print(f"Solved forcing: A={A:.6e}  B={B:.6e}   cond(M)={condM:.3e}")
print(f"Check at tc: F(tc)={F_tc:.3e}   F'(tc)={Fp_tc:.3e}")
print("Roots near tc BEFORE σ-step:")
print(roots0)

# If we have at least 2 roots, define separation of the closest pair
def closest_pair_sep(roots, center):
    if len(roots) < 2:
        return np.nan, (np.nan, np.nan)
    r = np.sort(roots)
    # choose pair minimizing distance to center in midpoint sense
    best = None
    best_metric = np.inf
    for i in range(len(r)-1):
        mid = 0.5*(r[i]+r[i+1])
        metric = abs(mid-center)
        if metric < best_metric:
            best_metric = metric
            best = (r[i], r[i+1])
    z1,z2 = best
    return abs(z2-z1), best

sep0, pair0 = closest_pair_sep(roots0, tc)
print(f"Closest-pair separation before σ-step: sep0={sep0:.6e}  pair={pair0}")

print("\n================ σ-STEP SPLITTING SCAN ================")
print("dsigma | sep(ds) | dsep/dσ (finite diff)")
print("-------------------------------------------------------")

prev_sep = None
prev_ds  = None
for ds in DSIGMAS:
    Fds = sigma_flow(F, ds)
    roots_ds = local_roots(Fds, tc, radius=ROOT_RADIUS)
    sep_ds, pair_ds = closest_pair_sep(roots_ds, tc)
    if np.isnan(sep_ds):
        print(f"{ds: .1e} |  nan     |  nan   (roots={len(roots_ds)})")
        continue
    if prev_sep is None:
        d = np.nan
    else:
        d = (sep_ds - prev_sep)/(ds - prev_ds)
    print(f"{ds: .1e} | {sep_ds: .6e} | {d if np.isfinite(d) else np.nan: .6e}   pair={pair_ds}")
    prev_sep, prev_ds = sep_ds, ds

print("\nInterpretation:")
print("• If sep0 is ~0 and sep(ds) grows ~ linearly with dsigma -> unstable double-zero under σ-flow.")
print("• If sep0 ~0 and sep(ds) stays ~0 across dsigma -> neutral/protected (ordering-like).")
print("==========================================================================")

============== STEP 28 — TRUE DOUBLE-ZERO + σ-STABILITY ================
WINDOW=(60.0, 120.0)  N=8192  dt=0.007324218750
tc=111.452176  WIDTH=0.200
--------------------------------------------------------------------------
Solved forcing: A=-9.813188e-01  B=-3.491603e-02   cond(M)=2.500e+01
Check at tc: F(tc)=-8.033e-17   F'(tc)=-3.213e-14
Roots near tc BEFORE σ-step:
[111.1978355  111.452176   111.48414418 111.53360162]
Closest-pair separation before σ-step: sep0=3.196818e-02  pair=(np.float64(111.452176), np.float64(111.4841441808402))

================ σ-STEP SPLITTING SCAN ================
dsigma | sep(ds) | dsep/dσ (finite diff)
-------------------------------------------------------
 1.0e-05 |  3.093266e-02 |  nan   pair=(np.float64(111.45293702836834), np.float64(111.48386968487169))
 2.0e-05 |  2.954504e-02 | -1.387614e+02   pair=(np.float64(111.45403402594621), np.float64(111.48357906856523))
 5.0e-05 |  2.554792e-02 | -1.332373e+02   pair=(np.float64(111.4570373446641), np.float64(111.48258526786296))
 1.0e-04 |  1.656646e-02 | -1.796292e+02   pair=(np.float64(111.46292069620335), np.float64(111.47948715768723))
 2.0e-04 |  3.167971e-01 |  3.002307e+03   pair=(np.float64(111.20106130975508), np.float64(111.51785842281927))

Interpretation:
• If sep0 is ~0 and sep(ds) grows ~ linearly with dsigma -> unstable double-zero under σ-flow.
• If sep0 ~0 and sep(ds) stays ~0 across dsigma -> neutral/protected (ordering-like).
=========

139

# ================= STEP 27 — DOUBLE ZERO STABILITY UNDER σ-FLOW =================
# Single-cell, fully self-contained

import numpy as np
from numpy.fft import fft, ifft, fftfreq

# ----------------------------
# Parameters (editable safely)
# ----------------------------
WINDOW = (60.0, 120.0)
N = 8192
EDGE_DROP = 2

SIGMA0 = 0.06          # base sigma
DSIGMA = 1e-4          # infinitesimal sigma step

# Forced double-zero parameters (from STEP 26 HIT)
tc = 111.452176
A  = 0.3211
B  = 0.001315
WIDTH = 0.20

# ----------------------------
# Grid
# ----------------------------
t = np.linspace(WINDOW[0], WINDOW[1], N, endpoint=False)
dt = t[1] - t[0]
k = 2*np.pi*fftfreq(N, d=dt)

# ----------------------------
# Approximate Z(t)
# (Riemann–Siegel style proxy, deterministic & smooth)
# ----------------------------
def Z_base(t):
    return np.real(np.exp(1j * (t*np.log(t+1) - t)))

Z0 = Z_base(t)

# ----------------------------
# Gaussian forcing
# ----------------------------
def gauss(t, tc, w):
    return np.exp(-(t-tc)**2/(2*w**2))

def dgauss(t, tc, w):
    return -(t-tc)/(w**2) * gauss(t, tc, w)

Z_forced = Z0 + A*gauss(t, tc, WIDTH) + B*dgauss(t, tc, WIDTH)

# ----------------------------
# Heat / σ-flow operator
# ----------------------------
def sigma_flow(Z, ds):
    Zk = fft(Z)
    Zk *= np.exp(-(k**2)*ds)
    return np.real(ifft(Zk))

# ----------------------------
# Root finder near tc
# ----------------------------
def local_roots(Z, center, radius=0.6, max_roots=4):
    mask = np.abs(t-center) < radius
    tt = t[mask]
    ZZ = Z[mask]

    s = np.sign(ZZ)
    crossings = np.where(np.diff(s)!=0)[0]

    roots = []
    for i in crossings:
        x1,x2 = tt[i],tt[i+1]
        y1,y2 = ZZ[i],ZZ[i+1]
        if y2 != y1:
            roots.append(x1 - y1*(x2-x1)/(y2-y1))
        if len(roots) >= max_roots:
            break
    return np.array(roots)

# ----------------------------
# Measure before σ-step
# ----------------------------
roots0 = local_roots(Z_forced, tc)

# ----------------------------
# Apply infinitesimal σ-flow
# ----------------------------
Z_eps = sigma_flow(Z_forced, DSIGMA)
roots1 = local_roots(Z_eps, tc)

# ----------------------------
# Diagnostics
# ----------------------------
print("\n================ STEP 27 — DOUBLE ZERO STABILITY =================")
print(f"tc = {tc:.6f}   sigma0 = {SIGMA0}   dsigma = {DSIGMA}")
print("---------------------------------------------------------------")

print("Roots before σ-step:")
print(roots0)

print("\nRoots after σ-step:")
print(roots1)

if len(roots0)==2 and len(roots1)==2:
    sep0 = abs(roots0[1]-roots0[0])
    sep1 = abs(roots1[1]-roots1[0])
    growth = (sep1-sep0)/DSIGMA
    print("\nSeparation:")
    print(f"  before = {sep0:.6e}")
    print(f"  after  = {sep1:.6e}")
    print(f"  d(sep)/dσ ≈ {growth:.6e}")
else:
    print("\nWARNING: root count mismatch — instability or resolution issue")

print("\nInterpretation:")
print("• Immediate splitting with d(sep)/dσ > 0 → double zero unstable")
print("• sep remains ~0 → neutral / protected")
print("• root loss → violent instability")
print("===============================================================")


=============== STEP 27 — DOUBLE ZERO STABILITY =================
tc = 111.452176   sigma0 = 0.06   dsigma = 0.0001
---------------------------------------------------------------
Roots before σ-step:
[111.06665528 111.76386744]

Roots after σ-step:
[111.06656698 111.76396853]

Separation:
  before = 6.972122e-01
  after  = 6.974015e-01
  d(sep)/dσ ≈ 1.893970e+00

Interpretation:
• Immediate splitting with d(sep)/dσ > 0 → double zero unstable
• sep remains ~0 → neutral / protected
• root loss → violent instability
=====

140



